{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import platform\n",
    "import subprocess\n",
    "import warnings\n",
    "\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_harmonics as th\n",
    "import torch_harmonics.distributed as dist\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "\n",
    "from subs1_utils import *\n",
    "from subs1_utils import precompute_latitudes, bscst\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Variables\n",
    "In the following cell you can set the values of the variables relevant to the model. The details of each variable are included in the README. In most cases it is only necessary to set values for the standard variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Spectral Truncation Desired and Consistent\n",
    "###    Gausian Grid\n",
    "zw = 63\n",
    "kmax = 26\n",
    "\n",
    "cmap = 'turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check value for kmax.\n",
    "if kmax!=11 and kmax!=26:\n",
    "    raise Exception(\"Unexpected value for kmax\")\n",
    "\n",
    "# Check value for zw.\n",
    "# Afterwards, set mw, jmax, and imax values based on the value given to zw.\n",
    "match zw:\n",
    "    case 42:\n",
    "        mw = zw\n",
    "        jmax = 64\n",
    "        imax = 128\n",
    "    case 63:\n",
    "        mw = zw\n",
    "        jmax = 96\n",
    "        imax = 192\n",
    "    case 124:\n",
    "        mw = zw\n",
    "        jmax = 188\n",
    "        imax = 376\n",
    "    case _:\n",
    "        raise Exception(\"Unexpected value for zw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name a path in which to save the preprocess output files.\n",
    "preprocess_path = (\n",
    "    'preprocess'\n",
    "    + '__zw_' + str(zw)\n",
    "    + '__kmax_' + str(kmax)\n",
    "    + '\\\\'\n",
    ")\n",
    "\n",
    "# Create an appropriate datapath for the user's operating system.\n",
    "# Delete and recreate the path if it already existed.\n",
    "cwd = str(pathlib.Path().resolve()) + '\\\\'\n",
    "user_platform = platform.system()\n",
    "print(\"Setting output preprocess_path for\", user_platform)\n",
    "match user_platform:\n",
    "    case 'Windows':\n",
    "        subprocess.run(['rmdir', '/s', '/q', cwd+preprocess_path], shell=True)\n",
    "        subprocess.run(['mkdir', cwd+preprocess_path], shell=True)\n",
    "    case 'Darwin':\n",
    "        subprocess.call(['rm','-r', cwd+preprocess_path])\n",
    "        subprocess.check_output(['mkdir', cwd+preprocess_path])\n",
    "    case _:\n",
    "        raise Exception(\"Use case for this system/OS is not implemented.\")\n",
    "print(\"preprocess_path =\", preprocess_path)\n",
    "print(\"fullpath = \", cwd+preprocess_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup necessary element for interpolation onto model Gaussian Grid\n",
    "# Get the Gaussian latitudes on equally spaced longitudes (xr.dataset)\n",
    "cost_lg, wlg, lats = precompute_latitudes(jmax)\n",
    "lats = 90-180*lats/(np.pi)\n",
    "lons = np.linspace(0.0,360.0-360.0/imax,imax)\n",
    "dlatlon = xr.Dataset({\"lat\": lats, \"lon\": lons})\n",
    "\n",
    "# Instantiate  grid to spectral (dsht) and spectral to grid (disht) transforms\n",
    "#\n",
    "vsht = th.RealVectorSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)\n",
    "dsht = dist.DistributedRealSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)\n",
    "disht = dist.DistributedInverseRealSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)\n",
    "dvsht = dist.DistributedRealVectorSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)\n",
    "divsht = dist.DistributedInverseRealVectorSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grab Topography Data\n",
    "###\n",
    "url_topo = 'http://research.jisao.washington.edu/data_sets/elevation/elev.0.75-deg.nc'\n",
    "ds_topo = xr.open_dataset(url_topo + '#mode=bytes', decode_times = False) # adding #mode=bytes because netcdf4 non-opendap URLrequeriment\n",
    "del ds_topo['time']\n",
    "data = ds_topo.data.squeeze()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = np.linspace(-np.pi, np.pi, data.shape[1])\n",
    "lat = np.linspace(np.pi/2., -np.pi/2., data.shape[0])\n",
    "Lon, Lat = np.meshgrid(lon, lat)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(1, 1, 1, projection='mollweide')\n",
    "cs = ax.pcolormesh(Lon, Lat, data, cmap=cmap)\n",
    "ax.set_title(\"Elevation map 0.75â—¦\")\n",
    "ax.grid(True)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "fig.colorbar(cs, ax=ax, shrink=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regridder_topog = xe.Regridder(data, dlatlon,'bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topog_gg = regridder_topog(data)*9.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topog_gg_dev = torch.from_numpy(np.where(topog_gg < 0.0, 0.0, topog_gg))\n",
    "coeffs = dsht(topog_gg_dev)\n",
    "topog_gg_r = disht(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the spectral coefficients for topography to be read by\n",
    "# the AGCM as a pickle file\n",
    "#\n",
    "torch.save(coeffs,preprocess_path+'topog.spectral.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# Surface temp used to derive 3-D temperature field for\n",
    "# Newtonian Relaxation\n",
    "#\n",
    "#\n",
    "ftemp = 'http://psl.noaa.gov/thredds/dodsC/Datasets/ncep.reanalysis/Monthlies/surface/air.sig995.mon.mean.nc'\n",
    "Dtemp = xr.open_dataset(ftemp,autoclose=True)\n",
    "Dtemp\n",
    "#\n",
    "# Field above is monthly 0.995 sigma level data\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dtemp.air[100,:,:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Need to set up vertical structure of back-ground temp based on\n",
    "# first sigma level in put. Will need model vertical structure\n",
    "# from subs1_utils\n",
    "#\n",
    "# First Calculate Climatology\n",
    "#\n",
    "tsurf_climo = Dtemp.air.groupby('time.month').mean(dim='time')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then interpolate to Gaussian grid\n",
    "#\n",
    "regridder_temp = xe.Regridder(tsurf_climo[1,:,:],dlatlon,'bilinear')\n",
    "#\n",
    "tsurf_feb = regridder_temp(tsurf_climo[1,:,:])\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsurf_feb.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsurf_feb_zonalmean = tsurf_feb.mean(dim='lon')\n",
    "tsurf_feb_zonalmean.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Now generature the vertical strucuture of temperature\n",
    "# will neeed model vertical structure (si(kmax))\n",
    "#\n",
    "delsig, si, sl, sikap, slkap, cth1, cth2, r1b, r2b = bscst(kmax)\n",
    "#\n",
    "#\n",
    "temp_spec = torch.from_numpy(np.zeros((kmax,zw,mw)))\n",
    "temp_gg = np.zeros((kmax,jmax,imax))\n",
    "#\n",
    "#   Radiative equilibrium temperature\n",
    "#       varying surface temperature decreasing with\n",
    "#       height with a lapse rate dTe/dz approx = -rlaps degrees/m\n",
    "#       to a stratospheric temperature of tstrat\n",
    "#\n",
    "rlaps=6.8*1.0e-03\n",
    "h0 = 8.2e+03\n",
    "tstrat = 205.0 # fixed stratospheric temperature\n",
    "#\n",
    "#for ii in range(n_lamda):\n",
    "#    temp_gg[kmax-1,:,ii] = tsurf_feb_zonalmean[:].values + 273.16 # Uncomment if\n",
    "                                                        # only using zonal mean surface\n",
    "                                                        # temperature\n",
    "temp_gg[kmax-1,:,:] = tsurf_feb.values + 273.16 # Uncomment if using full surface \n",
    "                                                 # temperature\n",
    "for k in np.arange(1, kmax, 1, dtype=int):\n",
    "    temp_gg[k,:,:] = temp_gg[kmax-1,:,:] + h0*rlaps*np.log(sl[k])\n",
    "#\n",
    "temp_gg[:,:,imax-1] = temp_gg[:,:,0]\n",
    "temp_gg = np.where(temp_gg < 205.0, 205.0, temp_gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lon, Lat = np.meshgrid(lons, lats)\n",
    "plt.pcolormesh(Lon, Lat, temp_gg[20,:,:]-273.16, cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_coeffs = dsht(torch.from_numpy(temp_gg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(temp_coeffs,preprocess_path+'temp.spectral.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "ftemp = 'http://psl.noaa.gov/thredds/dodsC/Datasets/ncep.reanalysis/Monthlies/surface_gauss/pres.sfc.mon.mean.nc'\n",
    "Dps = xr.open_dataset(ftemp,autoclose=True)\n",
    "Dps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psmean = Dps.pres.groupby('time.month').mean(dim='time')\n",
    "(psmean[1]/100).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnps = np.log(psmean[1]/(1000*100))\n",
    "lnps.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then interpolate to Gaussian grid\n",
    "#\n",
    "regridder_lnps = xe.Regridder(lnps,dlatlon,'bilinear')\n",
    "#\n",
    "lnps_feb = regridder_lnps(lnps)\n",
    "lnps_feb[:,imax-1] = lnps_feb[:,imax-2]\n",
    "lnps_feb.plot()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnps_coeffs = dsht(torch.from_numpy(lnps_feb.values))\n",
    "torch.save(lnps_coeffs,preprocess_path+'lnps.spectral.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# possible prescribed heating\n",
    "#\n",
    "ftemp = 'http://psl.noaa.gov/thredds/dodsC/Datasets/cmap/enh/precip.mon.mean.nc'\n",
    "Dprec = xr.open_dataset(ftemp,autoclose=True)\n",
    "Dprec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "prec_clim = Dprec.precip.groupby('time.month').mean(dim='time')\n",
    "prec_anom = Dprec.precip.groupby('time.month') - prec_clim\n",
    "#\n",
    "# ENSO Warm years\n",
    "wyrs = ['1983','1987','1988','1992','1995','1998','2003','2005','2007','2010','2015','2016','2019']\n",
    "wyrs = ['1998','1998','1998','1998','1998','1998','1998','1998','1998','1998','1998','1998','1998']\n",
    "anom = prec_anom[0]*0.0\n",
    "for k in range(13):\n",
    "    #anom = anom + prec_anom.sel(time=slice(wyrs[k]+'-01-01',wyrs[k]+'-03-01')).mean(dim='time')\n",
    "    anom = anom + prec_anom.sel(time=wyrs[k]+'-02-01')\n",
    "rain_anom = anom/13.0\n",
    "rain_anom.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Convert rainfall anomaly into a hearting rate that can\n",
    "# applied to the temperature equation (i.e., Q/Cp) and distribute\n",
    "# in the vertical\n",
    "#\n",
    "vert_struc = np.zeros(kmax) # whatever user wants\n",
    "#                                 kmax is lowest level and\n",
    "#                                 0 is the upper most level of\n",
    "#                                 the atmosphere\n",
    "heat = torch.zeros((kmax,jmax,imax),dtype=torch.float64)\n",
    "#\n",
    "if (kmax == 11):\n",
    "    vert_struc[0] = 0.0\n",
    "    vert_struc[1] = 0.1\n",
    "    vert_struc[2] = 0.2\n",
    "    vert_struc[3] = 1.5\n",
    "    vert_struc[4] = 1.9\n",
    "    vert_struc[5] = 1.5\n",
    "    vert_struc[6] = 0.9\n",
    "    vert_struc[7] = 0.5\n",
    "    vert_struc[8] = 0.2\n",
    "    vert_struc[9] = 0.1\n",
    "    vert_struc[10] = 0.0\n",
    "#\n",
    "if (kmax == 26):\n",
    "    vert_struc[0] = 0.0\n",
    "    vert_struc[1] = 0.0\n",
    "    vert_struc[2] = 0.0\n",
    "    vert_struc[3] = 0.0\n",
    "    vert_struc[4] = 0.0\n",
    "    vert_struc[5] = 0.25\n",
    "    vert_struc[6] = 0.5\n",
    "    vert_struc[7] = 0.75\n",
    "    vert_struc[8] = 1.0\n",
    "    vert_struc[9] = 1.5\n",
    "    vert_struc[10] = 1.75\n",
    "    vert_struc[11] = 1.75\n",
    "    vert_struc[12] = 1.75\n",
    "    vert_struc[13] = 2.0\n",
    "    vert_struc[14] = 2.0\n",
    "    vert_struc[15] = 2.0\n",
    "    vert_struc[16] = 2.0\n",
    "    vert_struc[17] = 1.75\n",
    "    vert_struc[18] = 1.75\n",
    "    vert_struc[19] = 1.5\n",
    "    vert_struc[20] = 1.25\n",
    "    vert_struc[21] = 0.75\n",
    "    vert_struc[22] = 0.5\n",
    "    vert_struc[23] = 0.25\n",
    "    vert_struc[24] = 0.0\n",
    "    vert_struc[25] = 0.0\n",
    "#\n",
    "# Need to ensure that vertical integral normalizes to 1.0\n",
    "rnorm = (vert_struc*delsig).sum()\n",
    "vert_struc = vert_struc/rnorm\n",
    "#\n",
    "# interpolate to Gaussian grid\n",
    "#\n",
    "regridder_oi2 = xe.Regridder(rain_anom,dlatlon,'bilinear')\n",
    "#\n",
    "tmp = regridder_oi2(rain_anom)\n",
    "tmp = np.where(tmp < 0.0, 0.0, tmp)\n",
    "#\n",
    "dheat = xr.Dataset({'heat': (['lat','lon'],tmp)}, \n",
    "                        coords={'lat': lats, 'lon': lons})\n",
    "globz = dheat.heat.mean(dim='lon')\n",
    "globm = globz.mean(dim='lat')\n",
    "tmp = (dheat.heat - globm).values\n",
    "tmp_hold = tmp\n",
    "#\n",
    "#\n",
    "# convert to heating and multiple by vertical structure\n",
    "#\n",
    "Lv = 2.5e+06\n",
    "rhow = 1000.0\n",
    "Cp = 1005.0\n",
    "Ps = 101325.0\n",
    "grav = 9.8\n",
    "beta = (Lv*rhow/Cp)*(grav/Ps)/(1000.0*86400.0)\n",
    "tropics = np.exp((-Lat*Lat)/1000.0) # limit forcing to tropics\n",
    "tmp = tropics*tmp\n",
    "#\n",
    "# Transform forward and backward to reduce forcing at unresolved scales\n",
    "#\n",
    "tmpspec = dsht(torch.from_numpy(tmp))\n",
    "tmp = disht(tmpspec)\n",
    "#\n",
    "for k in range(kmax):\n",
    "    heat[k,:,:] = (tmp[:,:]*vert_struc[k]*beta) # in K/sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Lon, Lat = np.meshgrid(lons, lats)\n",
    "plt.pcolormesh(Lon, Lat, heat[20], cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Lon, Lat = np.meshgrid(lons, lats)\n",
    "plt.pcolormesh(Lon, Lat, tmp-tmp_hold, cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "torch.save(heat,preprocess_path+'heat.ggrid.pt') # South-to-North same as topog data\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lon, Lat = np.meshgrid(lons, lats)\n",
    "landsea = np.where(topog_gg <= 0.0, 0.0,1.0)\n",
    "plt.pcolormesh(Lon, Lat, landsea, cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "torch.save(landsea,preprocess_path+'landsea.ggrid.pt') \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# The remaining cells only need to be executed if prescribed background\n",
    "# state is being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def press_to_sig(kmax,imax,jmax,press_data,press_levels,ps,slmodel,kmax_model):\n",
    "    # \n",
    "    # first convert pressure data to sigma using ps\n",
    "    #\n",
    "    sig_levels = torch.zeros((kmax,jmax,imax),dtype=torch.float64) # sigma levels of input data\n",
    "    sig_data = torch.zeros((kmax_model,jmax,imax),dtype=torch.float64) # output on model sigma levels\n",
    "    slmap = torch.zeros((kmax_model,jmax,imax),dtype=torch.float64) # model sigma levels but for all j & i\n",
    "    for k in range(kmax):\n",
    "        sig_levels[k,:,:] = press_levels[k]/ps[:,:] # sig_levels depends on k,j & i\n",
    "    for k in range(kmax_model):\n",
    "        slmap[k,:,:] = torch.tensor(slmodel[k]) \n",
    "    #\n",
    "    # now at each j & i to interpolate to the appropriate model sigma level\n",
    "    # Use log(sig) for interpolation\n",
    "    #\n",
    "    for isig in range(kmax_model):\n",
    "        for ipress in np.arange(kmax-1, -1, -1, dtype=int):\n",
    "            foo_up = torch.gt(slmap[isig],sig_levels[ipress-1])\n",
    "            foo_dn = torch.lt(slmap[isig],sig_levels[ipress])\n",
    "            # test if appropriate press level found\n",
    "            foo_up = 1*foo_up\n",
    "            foo_dn = 1*foo_dn\n",
    "            foo = foo_up + foo_dn\n",
    "            found = ( foo == 2 )\n",
    "            found = 1*found\n",
    "            ### found = 1 level found ; found = 0 level not found\n",
    "            denom = torch.log(sig_levels[ipress])\\\n",
    "                            - torch.log(sig_levels[ipress-1])\n",
    "            numer1 = torch.log(sig_levels[ipress])\\\n",
    "                            - torch.log(slmap[isig])\n",
    "            numer2 = torch.log(slmap[isig])\\\n",
    "                            - torch.log(sig_levels[ipress-1])\n",
    "            foo = numer1*press_data[ipress-1]/denom + numer2*press_data[ipress]/denom\n",
    "            sig_data[isig] = found*(foo) + (1-found)*sig_data[isig]\n",
    "    #\n",
    "    #\n",
    "    # Need to check if model sigma level is below reanalysis lowest sigma level\n",
    "    #\n",
    "    for isig in range(kmax_model):\n",
    "        foo_dn = torch.gt(slmap[isig],sig_levels[kmax-1])\n",
    "        foo_dn = 1*foo_dn\n",
    "        sig_data[isig] = foo_dn*press_data[kmax-1] + (1-foo_dn)*sig_data[isig]\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    # Need to check if model sigma level is above reanalysis highest sigma level\n",
    "    #\n",
    "    for isig in range(kmax_model):\n",
    "        foo_up = torch.lt(slmap[isig],sig_levels[0])\n",
    "        foo_up = 1*foo_up\n",
    "        sig_data[isig] = foo_up*press_data[0] + (1-foo_up)*sig_data[isig]\n",
    "    #\n",
    "    return sig_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# The remaining cells only need to be executed if prescribed background\n",
    "# state is being used\n",
    "#\n",
    "ftemp = 'http://psl.noaa.gov/thredds/dodsC/Datasets/ncep.reanalysis/Monthlies/pressure/vwnd.mon.mean.nc'\n",
    "Dvwnd = xr.open_dataset(ftemp,autoclose=True)\n",
    "ftemp = 'http://psl.noaa.gov/thredds/dodsC/Datasets/ncep.reanalysis/Monthlies/pressure/uwnd.mon.mean.nc'\n",
    "Duwnd = xr.open_dataset(ftemp,autoclose=True)\n",
    "ftemp = 'http://psl.noaa.gov/thredds/dodsC/Datasets/ncep.reanalysis/Monthlies/pressure/air.mon.mean.nc'\n",
    "Dair = xr.open_dataset(ftemp,autoclose=True)\n",
    "uwnd_clim = Duwnd.uwnd.groupby('time.month').mean(dim='time')\n",
    "vwnd_clim = Dvwnd.vwnd.groupby('time.month').mean(dim='time')\n",
    "air_clim = Dair.air.groupby('time.month').mean(dim='time')\n",
    "obs_levels = np.flipud(Dair['level'].values)\n",
    "kobs = np.size(obs_levels)\n",
    "#\n",
    "# Interpolate u & v to Gaussian Grid\n",
    "#\n",
    "lnps_feb = disht(lnps_coeffs) # inverse tranform applied here to limit\n",
    "                             # unresolved scales\n",
    "ps_feb = (torch.exp(lnps_feb)*1000.0) # surface pressure in mb on Gaussian grid\n",
    "#\n",
    "#\n",
    "regridder_oi2 = xe.Regridder(Duwnd.uwnd,dlatlon,'bilinear')\n",
    "upress_gg = torch.zeros((kobs,jmax,imax),dtype=torch.float64)\n",
    "vpress_gg = torch.zeros((kobs,jmax,imax),dtype=torch.float64)\n",
    "airpress_gg = torch.zeros((kobs,jmax,imax),dtype=torch.float64)\n",
    "for k in range(kobs):\n",
    "    upress_gg[kobs-k-1] = torch.from_numpy((regridder_oi2(uwnd_clim[1,k])).values)\n",
    "    upress_gg[kobs-k-1,:,imax-2] = upress_gg[kobs-k-1,:,imax-3]\n",
    "    upress_gg[kobs-k-1,:,imax-1] = upress_gg[kobs-k-1,:,imax-2]\n",
    "    upress_gg[kobs-k-1,:,0] = upress_gg[kobs-k-1,:,1]\n",
    "    vpress_gg[kobs-k-1] = torch.from_numpy((regridder_oi2(vwnd_clim[1,k])).values)\n",
    "    vpress_gg[kobs-k-1,:,imax-2] = vpress_gg[kobs-k-1,:,imax-3]\n",
    "    vpress_gg[kobs-k-1,:,imax-1] = vpress_gg[kobs-k-1,:,imax-2]\n",
    "    vpress_gg[kobs-k-1,:,0] = vpress_gg[kobs-k-1,:,1]\n",
    "    airpress_gg[kobs-k-1] = torch.from_numpy((regridder_oi2(air_clim[1,k])).values) + 273.16\n",
    "    airpress_gg[kobs-k-1,:,imax-2] = airpress_gg[kobs-k-1,:,imax-3]\n",
    "    airpress_gg[kobs-k-1,:,imax-1] = airpress_gg[kobs-k-1,:,imax-2]\n",
    "    airpress_gg[kobs-k-1,:,0] = airpress_gg[kobs-k-1,:,1]\n",
    "#\n",
    "#\n",
    "# Interpolate from Pressure to Sigma Levels\n",
    "#\n",
    "usig_gg = press_to_sig(kobs,imax,jmax,upress_gg,obs_levels,ps_feb,sl,kmax)\n",
    "vsig_gg = press_to_sig(kobs,imax,jmax,vpress_gg,obs_levels,ps_feb,sl,kmax)\n",
    "tsig_gg = press_to_sig(kobs,imax,jmax,airpress_gg,obs_levels,ps_feb,sl,kmax)\n",
    "tsig_gg = torch.where(tsig_gg < 205.0, 205.0, tsig_gg) ### This probably can be removed\n",
    "                                                    ### with improved vertical resolution\n",
    "#\n",
    "#\n",
    "# Need to apply forward and backward spectral transform to ensure that\n",
    "# there is no unresolved forcing from the prescribed background state\n",
    "#\n",
    "tmpspec = dsht(usig_gg)\n",
    "usig_gg = disht(tmpspec)\n",
    "tmpspec = dsht(vsig_gg)\n",
    "vsig_gg = disht(tmpspec)\n",
    "tmpspec = dsht(tsig_gg)\n",
    "tsig_gg = disht(tmpspec)\n",
    "#\n",
    "# convert u & v into spectral vort & divergence\n",
    "#\n",
    "zmn,dmn = vortdivspec(vsht,usig_gg,vsig_gg,kmax,mw,zw)\n",
    "#\n",
    "# Transform Spectral Vorticity and Divergence to Gaussian Grid\n",
    "#\n",
    "vortsig_gg = disht(zmn) ### This is relative vorticity\n",
    "divsig_gg = disht(dmn)\n",
    "#\n",
    "qmn = lnps_coeffs\n",
    "dxq_gg,dyq_gg = gradq(divsht,qmn,mw,zw,imax,jmax)\n",
    "#\n",
    "#\n",
    "# Now write climo data\n",
    "#\n",
    "torch.save(usig_gg,preprocess_path+'usig.ggrid.pt')\n",
    "torch.save(vsig_gg,preprocess_path+'vsig.ggrid.pt')\n",
    "torch.save(tsig_gg,preprocess_path+'tsig.ggrid.pt')\n",
    "torch.save(vortsig_gg,preprocess_path+'vortsig.ggrid.pt')\n",
    "torch.save(divsig_gg,preprocess_path+'divsig.ggrid.pt')\n",
    "torch.save(dxq_gg,preprocess_path+'dxq_gg.ggrid.pt')\n",
    "torch.save(dyq_gg,preprocess_path+'dyq_gg.ggrid.pt')\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Lon, Lat = np.meshgrid(lons, lats)\n",
    "plt.pcolormesh(Lon, Lat, tsig_gg[6], cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(divsig_gg[:,50,70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_gg = disht(temp_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Lon, Lat = np.meshgrid(lons, lats)\n",
    "footemp = tsig_gg - temp_gg\n",
    "plt.pcolormesh(Lon, Lat, tsig_gg[0], cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Lon, Lat = np.meshgrid(lons, lats)\n",
    "footemp = tsig_gg - temp_gg\n",
    "plt.pcolormesh(Lon, Lat, vsig_gg[0], cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Lev,Lat = np.meshgrid(-sl,lats)\n",
    "zonal_mean = usig_gg.mean(dim=2)\n",
    "foofoo = torch.transpose(zonal_mean, 0, 1)\n",
    "plt.pcolormesh(Lat, Lev, foofoo, cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Lev,Lon = np.meshgrid(-sl,lons)\n",
    "heating = heat[:,94,:]*86400\n",
    "foofoo = torch.transpose(heating, 0, 1)\n",
    "plt.pcolormesh(Lon, Lev, foofoo, cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(heat[:,33,70]*86400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Lev,Lat = np.meshgrid(-sl,lats)\n",
    "zonal_mean = vsig_gg.mean(dim=2)\n",
    "foofoo = torch.transpose(zonal_mean, 0, 1)\n",
    "plt.pcolormesh(Lat, Lev, foofoo, cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Lev,Lat = np.meshgrid(-sl,lats)\n",
    "zonal_mean = vortsig_gg.mean(dim=2)\n",
    "foofoo = torch.transpose(zonal_mean, 0, 1)\n",
    "plt.pcolormesh(Lat, Lev, foofoo, cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lon, Lat = np.meshgrid(lons, lats)\n",
    "plt.pcolormesh(Lon, Lat, ps_feb, cmap=cmap)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lon, Lat = np.meshgrid(lons, lats)\n",
    "plt.pcolormesh(Lon, Lat, vortsig_gg[10], cmap=cmap)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Lev,Lat = np.meshgrid(-sl,lats)\n",
    "zonal_mean = divsig_gg.mean(dim=2)\n",
    "foofoo = torch.transpose(zonal_mean, 0, 1)\n",
    "plt.pcolormesh(Lat, Lev, foofoo, cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agcm_environment_windows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
