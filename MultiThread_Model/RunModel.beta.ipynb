{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.captureWarnings(False)\n",
    "logging.getLogger('py.warnings').setLevel(logging.ERROR)\n",
    "from dask.distributed import Client, progress\n",
    "client = Client(n_workers=5, threads_per_worker=4, memory_limit='100GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import subprocess\n",
    "import sys\n",
    "import torch_harmonics as th\n",
    "import torch_harmonics.distributed as dist\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from subs1_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For MacOS is higher than 12.3+\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"Running on GPU\")\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS is activated:\",torch.backends.mps.is_built()) # Was the current version of PyTorch built with MPS activated?\n",
    "else:\n",
    "    print(\"Running  on CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This cell initializes the model\n",
    "###\n",
    "###     First Define all spectral grids\n",
    "###\n",
    "zw = 63 # zonal wave number\n",
    "mw = 63 # meridional wave number\n",
    "kmax = 26\n",
    "imax = 192\n",
    "jmax = 96\n",
    "steps_per_day = 216*1.5 ### Changing this number impliws time step changes and should\n",
    "#                       be implemented carefully\n",
    "###\n",
    "spec = (mw,zw,kmax)\n",
    "grid = (imax,jmax,kmax)\n",
    "#\n",
    "#\n",
    "# provide experiment name and data path for writing out data\n",
    "# datapath may need to be edited for your system\n",
    "#\n",
    "expname = 'TestT63L26_Dist'\n",
    "foo = str(subprocess.check_output(['whoami']))\n",
    "end = len(foo) - 3\n",
    "uname = foo[2:end]\n",
    "datapath = '/Users/'+uname+'/Work/AGCM/AGCM/tmp4/'+expname+'/'\n",
    "toffset = 0\n",
    "#\n",
    "# If restart see below settings\n",
    "#\n",
    "#toffset = 600*1 # toffset is the number of days that have already run\n",
    "#datapath_init = '/Users/'+uname+'/Work/AGCM/AGCM/tmp4/Restarts/Total/' # Location in restarts\n",
    "datapath_init = datapath #set equal to datapath if restarting in same directory\n",
    "#\n",
    "if ( toffset == 0): # Cold Start\n",
    "    subprocess.call(['rm','-r', datapath])\n",
    "    subprocess.check_output(['mkdir', datapath])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Gaussian latitudes and equally spaced longitudes\n",
    "#\n",
    "cost_lg, wlg, lats = precompute_latitudes(jmax)\n",
    "lats = 90-180*lats/(np.pi)\n",
    "lons = np.linspace(0.0,360.0-360.0/imax,imax)\n",
    "#\n",
    "# Instantiate grid to spectral (dsht) and spectral to grid (disht) distibuted transforms\n",
    "#\n",
    "vsht = th.RealVectorSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)\n",
    "dsht = dist.DistributedRealSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)\n",
    "disht = dist.DistributedInverseRealSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)\n",
    "dvsht = dist.DistributedRealVectorSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)\n",
    "divsht = dist.DistributedInverseRealVectorSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "# Initialize spectral fields (at rest or to be read in)\n",
    "def initialize(temp_newton,lnpsclim,kmax,mw,zw):\n",
    "    for k in range (kmax):\n",
    "        tmn1[k] = tmn1[k] + temp_newton[k]\n",
    "        tmn2[k] = tmn2[k] + temp_newton[k]\n",
    "        tmn3[k] = tmn3[k] + temp_newton[k]\n",
    "    qmn1 = lnpsclim\n",
    "    qmn2 = lnpsclim\n",
    "    qmn3 = lnpsclim\n",
    "    return tmn1,tmn2,tmn3,qmn1,qmn2,qmn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Initialization: Could read spectral restarts, or could\n",
    "#              start at rest. If wanting to use grid point see\n",
    "#              jupyter notebook preprocess\n",
    "#              \n",
    "#\n",
    "# Implement at rest initial condition, but need coriolis since\n",
    "# model predicts total vorticity\n",
    "#\n",
    "coriolis = np.broadcast_to([(4.0*np.pi/86400)*np.sin(lats[j,np.newaxis]*np.pi/180.0) for j in range(jmax)], (jmax, imax))\n",
    "#\n",
    "#\n",
    "# Initialize spectral fields (at rest or to be read in)\n",
    "# Need to read in background temperature data for Newtonian\n",
    "# Relaxation and possible initialization, see preprocess\n",
    "# for how to change source data or formulation.\n",
    "#\n",
    "temp_newton = torch.load('temp.spectral.pt') # newtonian \n",
    "#                                    relaxation temperature, spectral\n",
    "lnpsclim = torch.load('lnps.spectral.pt') # lnps climatology for damping\n",
    "#\n",
    "# Read Climatology on Gausian Grid\n",
    "#\n",
    "tclim_gg = torch.load('tsig.ggrid.pt')\n",
    "vortclim_gg = torch.load('vortsig.ggrid.pt')\n",
    "divclim_gg = torch.load('divsig.ggrid.pt')\n",
    "#\n",
    "divclim = dsht(divclim_gg)\n",
    "vortclim = dsht(vortclim_gg)\n",
    "tclim = dsht(tclim_gg)\n",
    "#\n",
    "zmn1 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "zmn2 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "if ( toffset > 0 ): # Restart\n",
    "    zmn1 = torch.load(datapath_init+'zmn1.spectral.pt')\n",
    "    zmn2 = torch.load(datapath_init+'zmn2.spectral.pt')\n",
    "zmn3 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "#\n",
    "dmn1 = torch.zeros((kmax,mw,zw),dtype=torch.complex128) \n",
    "dmn2 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "if ( toffset > 0 ): # Restart\n",
    "    dmn1 = torch.load(datapath_init+'dmn1.spectral.pt')\n",
    "    dmn2 = torch.load(datapath_init+'dmn2.spectral.pt')\n",
    "dmn3 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "#\n",
    "tmn1 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "tmn2 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "if ( toffset > 0 ): # Restart\n",
    "    tmn1 = torch.load(datapath_init+'tmn1.spectral.pt') \n",
    "    tmn2 = torch.load(datapath_init+'tmn2.spectral.pt')\n",
    "tmn3 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "#\n",
    "wmn1 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "wmn2 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "wmn3 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "#\n",
    "qmn1 = torch.zeros((mw,zw),dtype=torch.complex128)\n",
    "qmn2 = torch.zeros((mw,zw),dtype=torch.complex128)\n",
    "if ( toffset > 0 ): # Restart\n",
    "    qmn1 = torch.load(datapath_init+'qmn1.spectral.pt')\n",
    "    qmn2 = torch.load(datapath_init+'qmn2.spectral.pt')\n",
    "qmn3 = torch.zeros((mw,zw),dtype=torch.complex128)\n",
    "#\n",
    "#\n",
    "if ( toffset == 0 ): # Only do this if cold start\n",
    "    tmn1,tmn2,tmn3,qmn1,qmn2,qmn3 =\\\n",
    "    initialize(tclim,lnpsclim,kmax,mw,zw)\n",
    "#\n",
    "# Topography data - this should be spectral data or can be\n",
    "#                        initialized to zero. If grid point data\n",
    "#                        is desired see preprocess for how to\n",
    "#                        convert to spectral. \n",
    "#\n",
    "# Setting topography to zero here\n",
    "#\n",
    "###phismn = torch.zeros((mw,zw),dtype=torch.complex128)\n",
    "#\n",
    "# If non-zero topog read here\n",
    "#\n",
    "phismn = torch.load('topog.spectral.pt')\n",
    "#\n",
    "#\n",
    "# Adding heating here see preprocess.ipynb\n",
    "#\n",
    "####heat = torch.load('heat.ggrid.pt')\n",
    "#\n",
    "# or set to zero\n",
    "#\n",
    "heat = torch.zeros((kmax,jmax,imax),dtype=torch.float64)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Constants, parameters, vertical differencing parameters,\n",
    "### matricies for geopotential height, etc ...\n",
    "###\n",
    "delsig, si, sl, sikap, slkap, cth1, cth2, r1b, r2b = bscst(kmax)\n",
    "### The above code is in subs1_utils.py - vertical structure related\n",
    "### This code would need to be changed if the vertical resolution\n",
    "### is changed - could be done by simply specifying delsig in bscst\n",
    "###\n",
    "amtrx, cmtrx, dmtrx = mcoeff(kmax,si,sl,slkap,r1b,r2b,delsig)\n",
    "### The above code is for geopotential height and implicit scheme\n",
    "### in subs1_utils.py but unlikely any changes would be needed\n",
    "emtrx = inv_em(dmtrx,steps_per_day,kmax,mw,zw)\n",
    "### The above code\n",
    "### emtrix is used in the implicit time scheme, computed once here to save cpu time\n",
    "### changes unlikely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Preprocessing is complete - now time to run model\n",
    "#\n",
    "#\n",
    "# The Model Runs in 30-day chuncks - need to specify how many 30-day chunks to run\n",
    "tl = 30 ##### tl is the chunk size - typically 30 days, but for testing 3 is reasonable\n",
    "#\n",
    "# Suggested ichunk for time dependent models: 120\n",
    "#\n",
    "ae = 6.371E+06 # Earth radius\n",
    "tmnt = torch.zeros((tl,kmax,mw,zw),dtype=torch.complex128)\n",
    "zmnt = tmnt.detach().clone()\n",
    "dmnt = tmnt.detach().clone()\n",
    "qmnt = torch.zeros((tl,mw,zw),dtype=torch.complex128)\n",
    "wmnt = tmnt.detach().clone()\n",
    "#\n",
    "ddtdiv = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "ddtvort = ddtdiv.detach().clone()\n",
    "ttend = ddtdiv.detach().clone()\n",
    "#\n",
    "vort = torch.zeros((kmax,jmax,imax),dtype=torch.float64)\n",
    "div = ddtdiv .detach().clone()\n",
    "temp = ddtdiv.detach().clone()\n",
    "qdot = ddtdiv.detach().clone()\n",
    "#\n",
    "times = pd.date_range(start = '1950-01-01', end='2100-01-01', freq='D')\n",
    "# \n",
    "ichunk = 20\n",
    "#\n",
    "idays = tl * ichunk\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# Begin Time Loop\n",
    "#\n",
    "ii = 0\n",
    "savedat = 0\n",
    "daycount = 0\n",
    "total_days = 0\n",
    "nstep = idays*steps_per_day\n",
    "while ii < nstep:\n",
    "    ii = ii + 1\n",
    "    savedat = savedat + 1\n",
    "    zmnt[daycount] = zmnt[daycount] + zmn1/steps_per_day\n",
    "    dmnt[daycount] = dmnt[daycount] + dmn1/steps_per_day\n",
    "    tmnt[daycount] = tmnt[daycount] + tmn1/steps_per_day\n",
    "    qmnt[daycount] = qmnt[daycount] + qmn1/steps_per_day\n",
    "    wmnt[daycount] = wmnt[daycount] + wmn1/steps_per_day\n",
    "    if (savedat == steps_per_day): # post processing\n",
    "        #\n",
    "        # Call Postprocessing Routine as needed\n",
    "        #\n",
    "        print((dmn1[10,2,2],dmn1[9,2,1]))\n",
    "        daycount = daycount + 1\n",
    "        total_days = total_days + 1\n",
    "        print(['Day = ',total_days])\n",
    "        if (daycount == tl):\n",
    "            times_30day = times[total_days-tl+toffset:total_days+toffset]\n",
    "            postprocessing(disht,divsht,zmnt,dmnt,tmnt,qmnt,wmnt,\\\n",
    "                           phismn,amtrx,times_30day,mw,zw,\\\n",
    "                           kmax,imax,jmax,sl,lats,lons,tl,datapath)\n",
    "            tmnt = torch.zeros((tl,kmax,mw,zw),dtype=torch.complex128)\n",
    "            zmnt = torch.zeros((tl,kmax,mw,zw),dtype=torch.complex128)\n",
    "            dmnt = torch.zeros((tl,kmax,mw,zw),dtype=torch.complex128)\n",
    "            qmnt = torch.zeros((tl,mw,zw),dtype=torch.complex128)\n",
    "            wmnt = torch.zeros((tl,kmax,mw,zw),dtype=torch.complex128)\n",
    "            daycount = 0\n",
    "        savedat = 0\n",
    "    #\n",
    "    # Run model for one time step\n",
    "    #\n",
    "    # Spectral to grid transformation of needed fields:\n",
    "    #   Vorticity, divergence, temperature, U, V, \n",
    "    #   grad(ln(Ps)), Q prescibed heating\n",
    "    #\n",
    "    #\n",
    "    vort = disht(zmn2) ### This is the relative vorticity\n",
    "    div = disht(dmn2)\n",
    "    temp = disht(tmn2)\n",
    "    qdot = disht(wmn2)\n",
    "    u,v = uv(divsht,zmn2,dmn2,mw,zw,kmax,imax,jmax)\n",
    "    dxq,dyq = gradq(divsht,qmn2,mw,zw,imax,jmax)\n",
    "    #\n",
    "    # Non-Linear products\n",
    "    #\n",
    "    a,b,e,ut,vt,ri,wj,cbar,dbar = nlprod(u,v,vort,div,temp,dxq,dyq,heat,coriolis,delsig,si,sikap,slkap,\\\n",
    "                                         r1b,r2b,cth1,cth2,cost_lg,kmax,imax,jmax)\n",
    "    #\n",
    "    #\n",
    "    # Grid to spectral transformation of nlprod results\n",
    "    #\n",
    "    ddtdiv,ddtvort = vortdivspec(vsht,a,b,kmax,mw,zw)\n",
    "    zmn3 = - ddtvort\n",
    "    dmn3 = ddtdiv - lap_sht(dsht,e,mw,zw)\n",
    "    _,ttend = vortdivspec(vsht,ut,vt,kmax,mw,zw)\n",
    "    #\n",
    "    tmn3 = -ttend + dsht(ri)\n",
    "    wmn3 = dsht(wj) ### Prescribed heating converted to spectral\n",
    "    qmn3 = -dsht(cbar) ### Only cbar here since dbar is included in implicit or explicit\n",
    "    # \n",
    "    # Diffusion, Damping, Implicit or Explicit time differencing, Time filter\n",
    "    #\n",
    "    zmn3,dmn3,tmn3 = diffsn(zmn1,zmn3,dmn1,dmn3,tmn1,tmn3,mw,zw)\n",
    "    #\n",
    "    zmn3,dmn3,tmn3,qmn3 = damp_test(zmn1,zmn3,dmn1,dmn3,tmn1,tmn3,qmn1,qmn3,\\\n",
    "                          tclim,lnpsclim,vortclim,divclim,kmax,mw,zw)\n",
    "    #\n",
    "    dt = 86400.0/steps_per_day\n",
    "    #\n",
    "    zmn1,zmn2,zmn3,dmn1,dmn2,dmn3,tmn1,tmn2,tmn3,qmn1,qmn2,qmn3 = \\\n",
    "                        explicit(dt,amtrx,cmtrx,dmtrx,emtrx,\\\n",
    "                        zmn1,zmn2,zmn3,dmn1,dmn2,dmn3,tmn1,tmn2,\\\n",
    "                        tmn3,wmn1,wmn2,wmn3,qmn1,qmn2,qmn3,phismn,\\\n",
    "                        delsig,kmax,mw,zw)\n",
    "    ####\n",
    "    ## Reset zmn3, dmn3, tmn3,wmn3 & qmn3\n",
    "    ###\n",
    "    zmn3 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "    dmn3 = zmn3.detach().clone()\n",
    "    tmn3 = zmn3.detach().clone()\n",
    "    wmn3 = zmn3.detach().clone()\n",
    "    qmn3 = torch.zeros((mw,zw),dtype=torch.complex128)\n",
    "#\n",
    "# Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write spectral data for possible restart\n",
    "##\n",
    "torch.save(zmn1,datapath+'zmn1.spectral.pt')\n",
    "torch.save(zmn2,datapath+'zmn2.spectral.pt')\n",
    "torch.save(dmn1,datapath+'dmn1.spectral.pt')\n",
    "torch.save(dmn2,datapath+'dmn2.spectral.pt')\n",
    "torch.save(tmn1,datapath+'tmn1.spectral.pt')\n",
    "torch.save(tmn2,datapath+'tmn2.spectral.pt')\n",
    "torch.save(qmn1,datapath+'qmn1.spectral.pt')\n",
    "torch.save(qmn2,datapath+'qmn2.spectral.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
