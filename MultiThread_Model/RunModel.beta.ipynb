{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pathlib\n",
    "import platform\n",
    "import subprocess\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_harmonics as th\n",
    "import torch_harmonics.distributed as dist\n",
    "\n",
    "from subs1_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Glossary\n",
    "In the following cell you can set the values of the variables relevant to the model. The details of each variable are included below.\n",
    "\n",
    "\n",
    "## Standard Variables\n",
    "In most cases it is only necessary to set values for the standard variables.\n",
    "\n",
    "**zw** is the zonal wave number. For standard use, zw should be set to the value of either 42, 63, or 124. Setting the value for zw also sets default values for the following variables: mw, jmax, imax, and steps_per_day.\n",
    "<br>Set zw = 42, to set mw = 42, jmax = 64, imax = 128, and steps_per_day = 216.\n",
    "<br>Set zw = 63, to set mw = 63, jmax = 96, imax = 192, and steps_per_day = 324.\n",
    "<br>Set zw = 124, to set mw = 124, jmax = 188, imax = 376, and steps_per_day = 648.\n",
    "<br>Each of these variables (mw, jmax, imax, and steps_per_day) that is given a value in the advanced variables section will instead use that value.\n",
    "\n",
    "**kmax** is the number of vertical levels. The value of kmax should be 11 or 26 for standard use.\n",
    "\n",
    "**expname** is the name you want to be given to your experiment. When the data is saved to your computer, it will be saved in a folder with this name. Note that if you run this program twice with the same expname, your first experiment's data will be overwritten.\n",
    "\n",
    "**toffset** is the number of days that have already run when restarting.\n",
    "\n",
    "**datapath_init** is the directory in which files are saved in the case of a restart. Set this equal to the datapath if restarting in the same directory.\n",
    "\n",
    "\n",
    "## Advanced Variables\n",
    "While most cases only require setting the standard variables, some cases might require setting some or all advanced variables as well. The following variables should only be changed from their default value if a specific behavior is desired. An advanced variable set to the value of None will use the default case.\n",
    "\n",
    "**mw** is the meridional wave number. In the standard case this value is set equal to zw.\n",
    "\n",
    "**jmax** is the number of Gaussian latitudes. jmax = imax/2\n",
    "\n",
    "**imax** is the number of longitude grid points. imax >= 3 * zw + 1. imax must be an even number.\n",
    "\n",
    "**steps_per_day** is the number of time steps per day. It gives you the delta t in the time differencing scheme. The length of a day is 86400 seconds, so delta t = 86400/steps_per_day. Changing this number implies time step changes and should be implemented carefully. The values used in the standard case were determined expertimentally.\n",
    "\n",
    "**custom_path** is the full path of the folder in which you wish to save your data. If custom_path is set, expname is ignored. Note that this must be an existing folder.\n",
    "\n",
    "**custom_kmax** is used to safeguard against using unexpected values for the kmax. If custom_kmax is set, it will be used instead of kmax. By default the program only supports kmax with a value of either 11 or 26. Other values are implementable, but the user must modify subs1_utils.py routine bscst. If unclear email bkirtman@miami.edu for clarification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters.\n",
    "\n",
    "# Standard Variables\n",
    "zw = 63\n",
    "kmax = 26\n",
    "expname = 'TestT63L26_Dist'\n",
    "toffset = 0\n",
    "datapath_init = None\n",
    "\n",
    "# Advanced Variables\n",
    "mw = None\n",
    "jmax = None\n",
    "imax = None\n",
    "steps_per_day = None\n",
    "custom_path = None\n",
    "custom_kmax = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zw = 63 \n",
      "mw = 63 \n",
      "kmax = 26 \n",
      "jmax = 96 \n",
      "imax = 192 \n",
      "steps_per_day = 324\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model.\n",
    "\n",
    "# Set value of kmax if custom_kmax is used.\n",
    "if not(custom_kmax is None):\n",
    "    kmax = custom_kmax\n",
    "    print(\"Using custom value for kmax:\", kmax)\n",
    "# Otherwise check value for kmax.\n",
    "elif kmax!=11 and kmax!=26:\n",
    "    raise Exception(\"Unexpected value for kmax. Use custom_kmax and note that other values are implementable, but the user must modify subs1_utils.py routine bscst. If unclear email bkirtman@miami.edu for clarification.\")\n",
    "\n",
    "# Check value for zw.\n",
    "# Afterwards, set mw, jmax, imax, and steps_per_day values based on the value given to zw.\n",
    "# If a value is already given for one of the listed variables, use that instead.\n",
    "match zw:\n",
    "    case 42:\n",
    "        mw = 42 if (mw is None) else mw\n",
    "        jmax = 64 if (jmax is None) else jmax\n",
    "        imax = 128 if (imax is None) else imax\n",
    "        steps_per_day = 216 if (steps_per_day is None) else steps_per_day\n",
    "    case 63:\n",
    "        mw = 63 if (mw is None) else mw\n",
    "        jmax = 96 if (jmax is None) else jmax\n",
    "        imax = 192 if (imax is None) else imax\n",
    "        steps_per_day = 324 if (steps_per_day is None) else steps_per_day\n",
    "    case 124:\n",
    "        mw = 124 if (mw is None) else mw\n",
    "        jmax = 188 if (jmax is None) else jmax\n",
    "        imax = 376 if (imax is None) else imax\n",
    "        steps_per_day = 648 if (steps_per_day is None) else steps_per_day\n",
    "    case _:\n",
    "        if (mw is None) or (jmax is None) or (imax is None) or (steps_per_day is None):\n",
    "            raise Exception(\"Unexpected value for zw. Other values are implementable, but the user must specify values for mw, jmax, imax, and steps_per_day in the advanced variables section.\")\n",
    "print(\"zw =\", zw,\n",
    "      \"\\nmw =\", mw,\n",
    "      \"\\nkmax =\", kmax,\n",
    "      \"\\njmax =\", jmax,\n",
    "      \"\\nimax =\", imax,\n",
    "      \"\\nsteps_per_day =\", steps_per_day)\n",
    "\n",
    "spec = (mw,zw,kmax)\n",
    "grid = (imax,jmax,kmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory containing preprocess data was found. \n",
      "preprocess_path = preprocess__zw_63__kmax_26\\\n"
     ]
    }
   ],
   "source": [
    "# Set preprocess path.\n",
    "\n",
    "# Use this path whenever loading model data.\n",
    "# The preprocess file shares a directory with the model and saves its data to\n",
    "# a folder under that directory. This folder is named after the variable values in the data.\n",
    "preprocess_path = (\n",
    "    'preprocess'\n",
    "    + '__zw_' + str(zw)\n",
    "    + '__kmax_' + str(kmax)\n",
    "    + '\\\\'\n",
    ")\n",
    "\n",
    "cwd = str(pathlib.Path().resolve()) + '\\\\'\n",
    "folder = cwd+preprocess_path\n",
    "\n",
    "# Check that the path exists, throwing an exception if it doesn't.\n",
    "# folder = path.join(pathlib.Path().resolve(), preprocess_path)\n",
    "\n",
    "if path.isdir(folder):\n",
    "    print(\"Directory containing preprocess data was found.\",\n",
    "          \"\\npreprocess_path =\", preprocess_path)\n",
    "else:\n",
    "    raise Exception(\"Directory containing preprocess data was not found. \"\n",
    "                    + \"\\npreprocess_path = \" + str(preprocess_path)\n",
    "                    + \"\\nfull path = \" + str(folder)\n",
    "                    + \"\\nRun preprocess.ipynb prior to running the model.\"\n",
    "                    + \"\\nPreprocess must use the same variable values as the model.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting output datapath for Darwin\n",
      "datapath = /Users/bmapes/Documents/AGCM_Experiments/TestT63L26_Dist/ \n",
      "datapath_init = /Users/bmapes/Documents/AGCM_Experiments/TestT63L26_Dist/\n"
     ]
    }
   ],
   "source": [
    "# Set output datapath.\n",
    "\n",
    "# If custom_path was set, use that as the output datapath.\n",
    "# Otherwise create an appropriate datapath for the user's operating system.\n",
    "user_platform = platform.system() if (custom_path is None) else \"Custom Path\"\n",
    "print(\"Setting output datapath for\", user_platform)\n",
    "datapath = ''\n",
    "match user_platform:\n",
    "    case 'Custom Path':\n",
    "        datapath = custom_path\n",
    "    case 'Windows':\n",
    "        foo = str(subprocess.check_output(['whoami']))\n",
    "        end = len(foo) - 5\n",
    "        uname = foo[2:end].split(\"\\\\\\\\\")[1]\n",
    "        datapath = \"C:\\\\Users\\\\\" + uname + \"\\\\Documents\\\\AGCM_Experiments\\\\\" + expname + \"\\\\\"\n",
    "        if ( toffset == 0): # Cold Start\n",
    "            subprocess.run(['rmdir', '/s', '/q', datapath], shell=True)\n",
    "            subprocess.run(['mkdir', datapath], shell=True)\n",
    "    case 'Darwin':\n",
    "        foo = str(subprocess.check_output(['whoami']))\n",
    "        end = len(foo) - 3\n",
    "        uname = foo[2:end]\n",
    "        datapath = '/Users/'+uname+'/Documents/AGCM_Experiments/'+expname+'/'\n",
    "        if ( toffset == 0): # Cold Start\n",
    "            subprocess.call(['rm','-r', datapath])\n",
    "            subprocess.check_output(['mkdir', datapath])\n",
    "    case _:\n",
    "        raise Exception(\"Use case for this system/OS is not implemented. Consider using custom_path in the advanced variables.\")\n",
    "datapath_init = datapath if (datapath_init is None) else datapath\n",
    "print(\"datapath =\", datapath,\n",
    "      \"\\ndatapath_init =\", datapath_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU\n",
      "MPS is activated: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For MacOS is higher than 12.3+\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"Running on GPU\")\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS is activated:\",torch.backends.mps.is_built()) # Was the current version of PyTorch built with MPS activated?\n",
    "else:\n",
    "    print(\"Running  on CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Gaussian latitudes and equally spaced longitudes\n",
    "#\n",
    "cost_lg, wlg, lats = precompute_latitudes(jmax)\n",
    "lats = 90-180*lats/(np.pi)\n",
    "lons = np.linspace(0.0,360.0-360.0/imax,imax)\n",
    "#\n",
    "# Instantiate grid to spectral (dsht) and spectral to grid (disht) distibuted transforms\n",
    "#\n",
    "vsht = th.RealVectorSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)\n",
    "dsht = dist.DistributedRealSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)\n",
    "disht = dist.DistributedInverseRealSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)\n",
    "dvsht = dist.DistributedRealVectorSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)\n",
    "divsht = dist.DistributedInverseRealVectorSHT(jmax, imax, lmax=mw, mmax=zw, grid=\"legendre-gauss\", csphase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize spectral fields (at rest or to be read in)\n",
    "def initialize(temp_newton,lnpsclim,kmax,mw,zw):\n",
    "    for k in range (kmax):\n",
    "        tmn1[k] = tmn1[k] + temp_newton[k]\n",
    "        tmn2[k] = tmn2[k] + temp_newton[k]\n",
    "        tmn3[k] = tmn3[k] + temp_newton[k]\n",
    "    qmn1 = lnpsclim\n",
    "    qmn2 = lnpsclim\n",
    "    qmn3 = lnpsclim\n",
    "    return tmn1,tmn2,tmn3,qmn1,qmn2,qmn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Initialization: Could read spectral restarts, or could\n",
    "#              start at rest. If wanting to use grid point see\n",
    "#              jupyter notebook preprocess\n",
    "#              \n",
    "#\n",
    "# Implement at rest initial condition, but need coriolis since\n",
    "# model predicts total vorticity\n",
    "#\n",
    "coriolis = np.broadcast_to([(4.0*np.pi/86400)*np.sin(lats[j,np.newaxis]*np.pi/180.0) for j in range(jmax)], (jmax, imax))\n",
    "#\n",
    "#\n",
    "# Initialize spectral fields (at rest or to be read in)\n",
    "# Need to read in background temperature data for Newtonian\n",
    "# Relaxation and possible initialization, see preprocess\n",
    "# for how to change source data or formulation.\n",
    "#\n",
    "temp_newton = torch.load(cwd+preprocess_path+'temp.spectral.pt') # newtonian \n",
    "#                                    relaxation temperature, spectral\n",
    "lnpsclim = torch.load(cwd+preprocess_path+'lnps.spectral.pt') # lnps climatology for damping\n",
    "#\n",
    "# Read Climatology on Gausian Grid\n",
    "#\n",
    "tclim_gg = torch.load(cwd+preprocess_path+'tsig.ggrid.pt')\n",
    "vortclim_gg = torch.load(cwd+preprocess_path+'vortsig.ggrid.pt')\n",
    "divclim_gg = torch.load(cwd+preprocess_path+'divsig.ggrid.pt')\n",
    "#\n",
    "divclim = dsht(divclim_gg)\n",
    "vortclim = dsht(vortclim_gg)\n",
    "tclim = dsht(tclim_gg)\n",
    "#\n",
    "zmn1 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "zmn2 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "if ( toffset > 0 ): # Restart\n",
    "    zmn1 = torch.load(datapath_init+'zmn1.spectral.pt')\n",
    "    zmn2 = torch.load(datapath_init+'zmn2.spectral.pt')\n",
    "zmn3 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "#\n",
    "dmn1 = torch.zeros((kmax,mw,zw),dtype=torch.complex128) \n",
    "dmn2 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "if ( toffset > 0 ): # Restart\n",
    "    dmn1 = torch.load(datapath_init+'dmn1.spectral.pt')\n",
    "    dmn2 = torch.load(datapath_init+'dmn2.spectral.pt')\n",
    "dmn3 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "#\n",
    "tmn1 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "tmn2 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "if ( toffset > 0 ): # Restart\n",
    "    tmn1 = torch.load(datapath_init+'tmn1.spectral.pt') \n",
    "    tmn2 = torch.load(datapath_init+'tmn2.spectral.pt')\n",
    "tmn3 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "#\n",
    "wmn1 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "wmn2 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "wmn3 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "#\n",
    "qmn1 = torch.zeros((mw,zw),dtype=torch.complex128)\n",
    "qmn2 = torch.zeros((mw,zw),dtype=torch.complex128)\n",
    "if ( toffset > 0 ): # Restart\n",
    "    qmn1 = torch.load(datapath_init+'qmn1.spectral.pt')\n",
    "    qmn2 = torch.load(datapath_init+'qmn2.spectral.pt')\n",
    "qmn3 = torch.zeros((mw,zw),dtype=torch.complex128)\n",
    "#\n",
    "#\n",
    "if ( toffset == 0 ): # Only do this if cold start\n",
    "    tmn1,tmn2,tmn3,qmn1,qmn2,qmn3 =\\\n",
    "    initialize(tclim,lnpsclim,kmax,mw,zw)\n",
    "#\n",
    "# Topography data - this should be spectral data or can be\n",
    "#                        initialized to zero. If grid point data\n",
    "#                        is desired see preprocess for how to\n",
    "#                        convert to spectral. \n",
    "#\n",
    "# Setting topography to zero here\n",
    "#\n",
    "###phismn = torch.zeros((mw,zw),dtype=torch.complex128)\n",
    "#\n",
    "# If non-zero topog read here\n",
    "#\n",
    "phismn = torch.load(cwd+preprocess_path+'topog.spectral.pt')\n",
    "#\n",
    "#\n",
    "# Adding heating here see preprocess.ipynb\n",
    "#\n",
    "####heat = torch.load('heat.ggrid.pt')\n",
    "#\n",
    "# or set to zero\n",
    "#\n",
    "heat = torch.zeros((kmax,jmax,imax),dtype=torch.float64)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Constants, parameters, vertical differencing parameters,\n",
    "### matricies for geopotential height, etc ...\n",
    "###\n",
    "delsig, si, sl, sikap, slkap, cth1, cth2, r1b, r2b = bscst(kmax)\n",
    "### The above code is in subs1_utils.py - vertical structure related\n",
    "### This code would need to be changed if the vertical resolution\n",
    "### is changed - could be done by simply specifying delsig in bscst\n",
    "###\n",
    "amtrx, cmtrx, dmtrx = mcoeff(kmax,si,sl,slkap,r1b,r2b,delsig)\n",
    "### The above code is for geopotential height and implicit scheme\n",
    "### in subs1_utils.py but unlikely any changes would be needed\n",
    "emtrx = inv_em(dmtrx,steps_per_day,kmax,mw,zw)\n",
    "### The above code\n",
    "### emtrix is used in the implicit time scheme, computed once here to save cpu time\n",
    "### changes unlikely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Preprocessing is complete - now time to run model\n",
    "#\n",
    "#\n",
    "# The Model Runs in 30-day chuncks - need to specify how many 30-day chunks to run\n",
    "tl = 1 ##### tl is the chunk size - typically 30 days, but for testing 3 is reasonable\n",
    "#\n",
    "# Suggested ichunk for time dependent models: 120\n",
    "#\n",
    "ae = 6.371E+06 # Earth radius\n",
    "tmnt = torch.zeros((tl,kmax,mw,zw),dtype=torch.complex128)\n",
    "zmnt = tmnt.detach().clone()\n",
    "dmnt = tmnt.detach().clone()\n",
    "qmnt = torch.zeros((tl,mw,zw),dtype=torch.complex128)\n",
    "wmnt = tmnt.detach().clone()\n",
    "#\n",
    "ddtdiv = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "ddtvort = ddtdiv.detach().clone()\n",
    "ttend = ddtdiv.detach().clone()\n",
    "#\n",
    "vort = torch.zeros((kmax,jmax,imax),dtype=torch.float64)\n",
    "div = ddtdiv .detach().clone()\n",
    "temp = ddtdiv.detach().clone()\n",
    "qdot = ddtdiv.detach().clone()\n",
    "#\n",
    "times = pd.date_range(start = '1950-01-01', end='2100-01-01', freq='D')\n",
    "# \n",
    "ichunk = 20\n",
    "#ichunk = 2      # For shortening the runtime while testing.\n",
    "#\n",
    "idays = tl * ichunk\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# Begin Time Loop\n",
    "#\n",
    "ii = 0\n",
    "savedat = 0\n",
    "daycount = 0\n",
    "total_days = 0\n",
    "nstep = idays*steps_per_day\n",
    "while ii < nstep:\n",
    "    ii = ii + 1\n",
    "    savedat = savedat + 1\n",
    "    zmnt[daycount] = zmnt[daycount] + zmn1/steps_per_day\n",
    "    dmnt[daycount] = dmnt[daycount] + dmn1/steps_per_day\n",
    "    tmnt[daycount] = tmnt[daycount] + tmn1/steps_per_day\n",
    "    qmnt[daycount] = qmnt[daycount] + qmn1/steps_per_day\n",
    "    wmnt[daycount] = wmnt[daycount] + wmn1/steps_per_day\n",
    "    if (savedat == steps_per_day): # post processing\n",
    "        #\n",
    "        # Call Postprocessing Routine as needed\n",
    "        #\n",
    "        print((dmn1[10,2,2],dmn1[9,2,1]))\n",
    "        daycount = daycount + 1\n",
    "        total_days = total_days + 1\n",
    "        print(['Day = ',total_days])\n",
    "        print('Systime: ', datetime.datetime.now() )\n",
    "        if (daycount == tl):\n",
    "            times_30day = times[total_days-tl+toffset:total_days+toffset]\n",
    "            postprocessing(disht,divsht,zmnt,dmnt,tmnt,qmnt,wmnt,\\\n",
    "                           phismn,amtrx,times_30day,mw,zw,\\\n",
    "                           kmax,imax,jmax,sl,lats,lons,tl,datapath)\n",
    "            tmnt = torch.zeros((tl,kmax,mw,zw),dtype=torch.complex128)\n",
    "            zmnt = torch.zeros((tl,kmax,mw,zw),dtype=torch.complex128)\n",
    "            dmnt = torch.zeros((tl,kmax,mw,zw),dtype=torch.complex128)\n",
    "            qmnt = torch.zeros((tl,mw,zw),dtype=torch.complex128)\n",
    "            wmnt = torch.zeros((tl,kmax,mw,zw),dtype=torch.complex128)\n",
    "            daycount = 0\n",
    "        savedat = 0\n",
    "    #\n",
    "    # Run model for one time step\n",
    "    #\n",
    "    # Spectral to grid transformation of needed fields:\n",
    "    #   Vorticity, divergence, temperature, U, V, \n",
    "    #   grad(ln(Ps)), Q prescibed heating\n",
    "    #\n",
    "    #\n",
    "    vort = disht(zmn2) ### This is the relative vorticity\n",
    "    div = disht(dmn2)\n",
    "    temp = disht(tmn2)\n",
    "    qdot = disht(wmn2)\n",
    "    u,v = uv(divsht,zmn2,dmn2,mw,zw,kmax,imax,jmax)\n",
    "    dxq,dyq = gradq(divsht,qmn2,mw,zw,imax,jmax)\n",
    "    #\n",
    "    # Non-Linear products\n",
    "    #\n",
    "    a,b,e,ut,vt,ri,wj,cbar,dbar = nlprod(u,v,vort,div,temp,dxq,dyq,heat,coriolis,delsig,si,sikap,slkap,\\\n",
    "                                         r1b,r2b,cth1,cth2,cost_lg,kmax,imax,jmax)\n",
    "    #\n",
    "    #\n",
    "    # Grid to spectral transformation of nlprod results\n",
    "    #\n",
    "    ddtdiv,ddtvort = vortdivspec(vsht,a,b,kmax,mw,zw)\n",
    "    zmn3 = - ddtvort\n",
    "    dmn3 = ddtdiv - lap_sht(dsht,e,mw,zw)\n",
    "    _,ttend = vortdivspec(vsht,ut,vt,kmax,mw,zw)\n",
    "    #\n",
    "    tmn3 = -ttend + dsht(ri)\n",
    "    wmn3 = dsht(wj) ### Prescribed heating converted to spectral\n",
    "    qmn3 = -dsht(cbar) ### Only cbar here since dbar is included in implicit or explicit\n",
    "    # \n",
    "    # Diffusion, Damping, Implicit or Explicit time differencing, Time filter\n",
    "    #\n",
    "    zmn3,dmn3,tmn3 = diffsn(zmn1,zmn3,dmn1,dmn3,tmn1,tmn3,mw,zw)\n",
    "    #\n",
    "    zmn3,dmn3,tmn3,qmn3 = damp_test(zmn1,zmn3,dmn1,dmn3,tmn1,tmn3,qmn1,qmn3,\\\n",
    "                          tclim,lnpsclim,vortclim,divclim,kmax,mw,zw)\n",
    "    #\n",
    "    dt = 86400.0/steps_per_day\n",
    "    #\n",
    "    zmn1,zmn2,zmn3,dmn1,dmn2,dmn3,tmn1,tmn2,tmn3,qmn1,qmn2,qmn3 = \\\n",
    "                        explicit(dt,amtrx,cmtrx,dmtrx,emtrx,\\\n",
    "                        zmn1,zmn2,zmn3,dmn1,dmn2,dmn3,tmn1,tmn2,\\\n",
    "                        tmn3,wmn1,wmn2,wmn3,qmn1,qmn2,qmn3,phismn,\\\n",
    "                        delsig,kmax,mw,zw)\n",
    "    ####\n",
    "    ## Reset zmn3, dmn3, tmn3,wmn3 & qmn3\n",
    "    ###\n",
    "    zmn3 = torch.zeros((kmax,mw,zw),dtype=torch.complex128)\n",
    "    dmn3 = zmn3.detach().clone()\n",
    "    tmn3 = zmn3.detach().clone()\n",
    "    wmn3 = zmn3.detach().clone()\n",
    "    qmn3 = torch.zeros((mw,zw),dtype=torch.complex128)\n",
    "#\n",
    "# Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write spectral data for possible restart\n",
    "##\n",
    "torch.save(zmn1,datapath+'zmn1.spectral.pt')\n",
    "torch.save(zmn2,datapath+'zmn2.spectral.pt')\n",
    "torch.save(dmn1,datapath+'dmn1.spectral.pt')\n",
    "torch.save(dmn2,datapath+'dmn2.spectral.pt')\n",
    "torch.save(tmn1,datapath+'tmn1.spectral.pt')\n",
    "torch.save(tmn2,datapath+'tmn2.spectral.pt')\n",
    "torch.save(qmn1,datapath+'qmn1.spectral.pt')\n",
    "torch.save(qmn2,datapath+'qmn2.spectral.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
